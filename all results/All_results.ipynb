{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8a24cb",
   "metadata": {},
   "source": [
    "# Corpus Nummorum (CN) Data Challange Top 5 Accuarcies\n",
    "\n",
    "---\n",
    "\n",
    "**Goethe University Frankfurt am Main**\n",
    "\n",
    "Summer Semester 2023\n",
    "\n",
    "<br>\n",
    "\n",
    "## *Multimodal Fusion Model for  historical coin classification*\n",
    "\n",
    "---\n",
    "\n",
    "**Authors:** Bastian Rothenburger, Garegin Ktoian \n",
    "<br>\n",
    "\n",
    "**Contact:** Bastian Rothenburger ([s7072002@rz.uni-frankfurt.de](mailto:s7072002@rz.uni-frankfurt.de))<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650784bc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Table of Contents\n",
    "  - [Setup](#setup)\n",
    "- [1 Types](#1-types)\n",
    "  - [1.1 ResNet18 Base](#11-resnet18-base)\n",
    "    - [1.1.1 ImageEncoder Resnet18](#111-imageencoder-resnet18)\n",
    "    - [1.1.2 TextEncoder hidden size 10000](#112-textencoder-hidden-size-10000)\n",
    "    - [1.1.3 Fusion Model ResNet18 hidden size 10000](#113-fusion-model-resnet18-hidden-size-10000)\n",
    "  - [1.2 ResNet101 Base](#12-resnet101-base)\n",
    "    - [1.2.1 ImageEncoder ResNet101](#121-imageencoder-resnet101)\n",
    "    - [1.2.2 TextEncoder hidden size 12000](#122-textencoder-hidden-size-12000)\n",
    "    - [1.2.3 Fusion Model ResNet101 hidden size 12000](#123-fusion-model-resnet101-hidden-size-12000)\n",
    "- [2 Mints Multimodal](#2-mints-multimodal)\n",
    "  - [2.1 ResNet18 Base](#21-resnet18-base)\n",
    "    - [2.1.1 ImageEncoder ResNet18](#211-imageencoder-resnet18)\n",
    "    - [2.1.2 TextEncoder hidden size](#212-textencoder-hidden-size)\n",
    "    - [2.1.3 Fusion Model Resnet18 10000 hidden size](#213-fusion-model-resnet18-10000-hidden-size)\n",
    "  - [2.2 ResNet101 Base](#22-resnet101-base)\n",
    "    - [2.2.1 ImageEncoder ResNet 101](#221-imageencoder-resnet-101)\n",
    "    - [2.2.2 TextEncoder hidden size 12000](#222-textencoder-hidden-size-12000)\n",
    "    - [2.2.3 Fusion Model ResNet101 hidden size 12000](#223-fusion-model-resnet101-hidden-size-12000)\n",
    "- [3 Mints Image Only](#3-mints-image-only)\n",
    "  - [3.1 Resnet 18](#31-resnet-18)\n",
    "  - [3.2 ResNet50](#32-resnet50)\n",
    "  - [3.3 ResNet101](#33-resnet101)\n",
    "  - [3.4 ResNet 50 + Augments](#34-resnet-50-+-augments)\n",
    "  - [3.5 ResNet101 + Augemnts](#35-resnet101-+-augemnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a9531",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Setup\n",
    "\n",
    "---\n",
    "General Remarks:\n",
    "Some Modules have to be adjusted in order to work properly\n",
    "For all type models you have to change the defintion of TextEmbeddings in CoinDataset.\n",
    "For all Fusion models with another base than ResNet18 you have to change it in the constructur of \n",
    "the Fusion model class in the architectures modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d35f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gar43\\anaconda3\\envs\\ddc\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ModelTrainer import ModelTrainer\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights, resnet101, ResNet101_Weights \n",
    "from torchvision.models import swin_v2_b ,Swin_V2_B_Weights\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Architectures import TextClassefier, Transformer_TextClassifier, Fusion, Fusion_From_Scratch\n",
    "# Check GPU support on your machine.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f657c2",
   "metadata": {},
   "source": [
    "# 1 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cbf51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 10, 1536)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir = r\"C:\\Users\\gar43\\OneDrive\\Documents\\DataChallenge\\multimodal - Types\"\n",
    "model_save_path = dir +\"\\\\models\"\n",
    "\n",
    "# specifies image data \n",
    "train, val = dir+\"\\\\train.csv\", dir+\"\\\\val.csv\"\n",
    "\n",
    "# specifies language data\n",
    "train_emb, val_emb   = dir+'\\\\embeddings_train_alternative.npy', dir+'\\\\embeddings_val_alternative.npy'\n",
    "\n",
    "\n",
    "# specifies output feature size for imageencoder, textencoder and fusionmodel \n",
    "output_features = len(pd.read_csv(train, delimiter=',', skiprows=0, low_memory=False, encoding='iso-8859-1')[\"class\"].unique())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "set to true if you want to apply augments\n",
    "should increase performance slightly (roughly 2-3%)\n",
    "but also increases training time\n",
    "\"\"\"\n",
    "use_augments = False\n",
    "\n",
    "if use_augments:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])\n",
    "else:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c444e",
   "metadata": {},
   "source": [
    "## 1.1 ResNet18 Base\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f63c5b",
   "metadata": {},
   "source": [
    "## 1.1.1 ImageEncoder Resnet18\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b64907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2445\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 95]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bac9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8103\n",
      "Validation Top-5 Accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8103, device='cuda:0', dtype=torch.float64), 0.9767741935483871)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelImageEncoder_ResNet18.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61bcbc7",
   "metadata": {},
   "source": [
    "## 1.1.2 TextEncoder hidden size 10000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a0f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2445\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 95]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TextClassefier(input_size=1536, hidden_size=10000, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TextEncoder',\n",
    "            batch_size=4\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811c3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8190\n",
      "Validation Top-5 Accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTextEncoder.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcac6b7",
   "metadata": {},
   "source": [
    "## 1.1.3 Fusion Model ResNet18 hidden size 10000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e6a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2445\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 95]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "TextModel = TextClassefier(input_size=1536, hidden_size=10000, output_size=output_features)\n",
    "image_encoder = dir + \"\\\\models\\modelImageEncoder_ResNet18.tar\"\n",
    "text_encoder = dir + \"\\\\models\\modelTextEncoder.tar\"\n",
    "model = Fusion(image_encoder, text_encoder, TextModel, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TR0_Res18_types_with_des_78_multimodal',\n",
    "            batch_size=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d526834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8441\n",
      "Validation Top-5 Accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR0_Res18_types_with_des_78_multimodal.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa63611",
   "metadata": {},
   "source": [
    "# 1.2 ResNet101 Base\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858c1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"F:\\Users\\basti\\Documents\\Goethe Uni\\Data Challange\\top5_accs\\typesmodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114c2c2",
   "metadata": {},
   "source": [
    "## 1.2.1 ImageEncoder ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5af31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2445\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 95]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952be4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8245\n",
      "Validation Top-5 Accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8245, device='cuda:0', dtype=torch.float64), 0.9819354838709677)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelImageEncoder_ResNet101.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a75d7",
   "metadata": {},
   "source": [
    "## 1.2.2 TextEncoder hidden size 12000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472495a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2445\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 95]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TextClassefier(input_size=1536, hidden_size=12000, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TextEncoder',\n",
    "            batch_size=4\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec96ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8173\n",
      "Validation Top-5 Accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# because of our dataset construction the behavior is non deterministic, so we average over ten evaluation runs\n",
    "Solver.load(model_save_path+\"\\\\modelTextEncoder.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fc7ce",
   "metadata": {},
   "source": [
    "## 1.2.3 Fusion Model ResNet101 hidden size 12000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab99336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2446\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 95]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "TextModel = TextClassefier(input_size=1536, hidden_size=12000, output_size=output_features)\n",
    "image_encoder = model_save_path+\"\\\\modelImageEncoder_ResNet101.tar\"\n",
    "text_encoder = model_save_path+\"\\\\modelTextEncoder.tar\"\n",
    "model = Fusion(image_encoder, text_encoder, TextModel, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TR0_Res18_types_with_des_78_multimodal',\n",
    "            batch_size=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26e86ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8181\n",
      "Validation Top-5 Accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR0_Res101_types_with_des_78_multimodal.tar\")\n",
    "#Solver.evaluate(multimodal=True)\n",
    "\n",
    "\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ff46e",
   "metadata": {},
   "source": [
    "# 2 Mints Multimodal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04447aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"C:\\Users\\gar43\\OneDrive\\Documents\\DataChallenge\\Multimodal - Mints\"\n",
    "model_save_path = dir +\"\\\\models\"\n",
    "\n",
    "# specifies image data \n",
    "train, val = dir+\"\\\\train.csv\", dir+\"\\\\val.csv\"\n",
    "\n",
    "# specifies language data\n",
    "train_emb, val_emb   = dir+'\\\\embeddings_train.npy', dir+'\\\\embeddings_val.npy'\n",
    "\n",
    "# specifies output feature size for imageencoder, textencoder and fusionmodel \n",
    "output_features = len(pd.read_csv(train, delimiter=',', skiprows=0, low_memory=False, encoding='iso-8859-1')[\"class\"].unique())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "set to true if you want to apply augments\n",
    "should increase performance slightly (roughly 2-3%)\n",
    "but also increases training time\n",
    "\"\"\"\n",
    "use_augments = False\n",
    "\n",
    "if use_augments:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])\n",
    "else:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb8719",
   "metadata": {},
   "source": [
    "## 2.1 ResNet18 Base\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202d8e8",
   "metadata": {},
   "source": [
    "## 2.1.1 ImageEncoder ResNet18\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fc1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fac6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8126\n",
      "Validation Top-5 Accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8126, device='cuda:0', dtype=torch.float64), 0.9528383027522935)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelImageEncoder_ResNet18.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf213d2",
   "metadata": {},
   "source": [
    "## 2.1.2 TextEncoder hidden size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423ab04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 83]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = TextClassefier(input_size=1536, hidden_size=10000, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TextEncoder',\n",
    "            batch_size=4\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17eb7844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8817\n",
      "Validation Top-5 Accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTextEncoder.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185186d",
   "metadata": {},
   "source": [
    "## 2.1.3 Fusion Model Resnet18 10000 hidden size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089f9939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 83]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "TextModel = TextClassefier(input_size=1536, hidden_size=10000, output_size=output_features)\n",
    "image_encoder = model_save_path+\"\\\\modelImageEncoder_ResNet18.tar\"\n",
    "text_encoder = model_save_path+\"\\\\modelTextEncoder.tar\"\n",
    "model = Fusion(image_encoder, text_encoder, TextModel, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TR0_Res18_types_with_des_78_multimodal',\n",
    "            batch_size=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcce5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.9213\n",
      "Validation Top-5 Accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelFusion.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442eaf1d",
   "metadata": {},
   "source": [
    "# 2.2 ResNet101 Base\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fdc07",
   "metadata": {},
   "source": [
    "## 2.2.1 ImageEncoder ResNet 101\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b39291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = dir +\"\\\\models2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d5b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bfa08dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8492\n",
      "Validation Top-5 Accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8492, device='cuda:0', dtype=torch.float64), 0.9683199541284404)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelImageEncoder_ResNet101.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b261ef4",
   "metadata": {},
   "source": [
    "## 2.2.2 TextEncoder hidden size 12000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093acec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 83]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = TextClassefier(input_size=1536, hidden_size=12000, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TextEncoder',\n",
    "            batch_size=4\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73040b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.8849\n",
      "Validation Top-5 Accuracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTextEncoder.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cda69d",
   "metadata": {},
   "source": [
    "## 2.2.3 Fusion Model ResNet101 hidden size 12000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9188e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21008\n",
      "torch.Size([4, 3, 299, 299]) torch.Size([4, 83]) torch.Size([4, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "TextModel = TextClassefier(input_size=1536, hidden_size=12000, output_size=output_features)\n",
    "image_encoder = model_save_path+\"\\\\modelImageEncoder_ResNet101.tar\"\n",
    "text_encoder = model_save_path+\"\\\\modelTextEncoder.tar\"\n",
    "model = Fusion(image_encoder, text_encoder, TextModel, output_size=output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train, \n",
    "           train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='TR0_Res18_types_with_des_78_multimodal',\n",
    "            batch_size=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0eca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the average:\n",
      "Validation Top-1 Accuracy: 0.9378\n",
      "Validation Top-5 Accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelFusion.tar\")\n",
    "accs = []\n",
    "top_5_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    acc, top_5_acc = Solver.evaluate(multimodal=True, show=False)\n",
    "    accs.append(acc.cpu().numpy())\n",
    "    top_5_accs.append(top_5_acc)\n",
    "print('\\n This is the average:')    \n",
    "print(f'Validation Top-1 Accuracy: {np.array(accs).sum()/10:.4f}')\n",
    "print(f'Validation Top-5 Accuracy: {np.array(top_5_accs).sum()/10:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb3629",
   "metadata": {},
   "source": [
    "# 3 Mints Image Only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9a069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"F:\\Users\\basti\\Documents\\Goethe Uni\\Data Challange\"\n",
    "model_save_path = dir +\"\\\\models\"\n",
    "\n",
    "# specifies image data \n",
    "train, val = dir+\"\\\\train.csv\", dir+\"\\\\val.csv\"\n",
    "\n",
    "# specifies language data\n",
    "train_emb, val_emb   = dir+'\\\\embeddings_train.npy', dir+'\\\\embeddings_val.npy'\n",
    "\n",
    "# specifies output feature size for imageencoder, textencoder and fusionmodel \n",
    "output_features = len(pd.read_csv(train, delimiter=',', skiprows=0, low_memory=False, encoding='iso-8859-1')[\"class\"].unique())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "set to true if you want to apply augments\n",
    "should increase performance slightly (roughly 2-3%)\n",
    "but also increases training time\n",
    "\"\"\"\n",
    "use_augments = False\n",
    "\n",
    "if use_augments:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])\n",
    "else:\n",
    "    train_augmentations = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((299, 299))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ebef2",
   "metadata": {},
   "source": [
    "## 3.1 Resnet 18\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20b0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21593\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ee9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8058\n",
      "Validation Top-5 Accuracy: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8058, device='cuda:0', dtype=torch.float64), 0.9481553940749021)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR0_Res18.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38121a5c",
   "metadata": {},
   "source": [
    "## 3.2 ResNet50\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf190f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR0_Res50.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110aeb3",
   "metadata": {},
   "source": [
    "## 3.3 ResNet101\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77128c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21593\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981dfbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8291\n",
      "Validation Top-5 Accuracy: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8291, device='cuda:0', dtype=torch.float64), 0.9583566238121856)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR0_Res101.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6888a",
   "metadata": {},
   "source": [
    "## 3.4 ResNet 50 + Augments\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbc7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21593\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf7009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8432\n",
      "Validation Top-5 Accuracy: 0.9652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8432, device='cuda:0', dtype=torch.float64), 0.9652040245947456)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR5_Res50.tar\")\n",
    "Solver.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a9898",
   "metadata": {},
   "source": [
    "## 3.5 ResNet101 + Augemnts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d449bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "21593\n",
      "torch.Size([16, 3, 299, 299]) torch.Size([16, 83]) torch.Size([16, 1536])\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, output_features)\n",
    "\n",
    "# hyperparameters can be set here. Check ModelTrainer.py for details. If not specified differently default values of the Modeltrainer have been used \n",
    "Solver = ModelTrainer(model=model,  \n",
    "            train_path=train,\n",
    "            train_embedding_path=train_emb, \n",
    "            val_path=val,\n",
    "            val_embedding_path=val_emb, \n",
    "            train_augmentations=train_augmentations,\n",
    "            save_path=model_save_path,\n",
    "            postfix='ImageEncoder_ResNet18',\n",
    "            batch_size=16\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0867b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Accuracy: 0.8569\n",
      "Validation Top-5 Accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8569, device='cuda:0', dtype=torch.float64), 0.9700950251537171)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Solver.load(model_save_path+\"\\\\modelTR5_Res101.tar\")\n",
    "Solver.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
